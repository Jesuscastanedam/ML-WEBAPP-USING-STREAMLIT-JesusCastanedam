{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ImportError",
                    "evalue": "cannot import name 'is_quanto_available' from 'transformers.utils' (/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/utils/__init__.py)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Cargar el modelo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m model = \u001b[43mAutoModelForImageSegmentation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbriaai/RMBG-1.4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Función para preprocesar la imagen\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_image\u001b[39m(im: np.ndarray, model_input_size: \u001b[38;5;28mlist\u001b[39m) -> torch.Tensor:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:558\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[32m    557\u001b[39m     class_ref = config.auto_map[\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     model_class = \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     _ = hub_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    562\u001b[39m     \u001b[38;5;28mcls\u001b[39m.register(config.\u001b[34m__class__\u001b[39m, model_class, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:581\u001b[39m, in \u001b[36mget_class_from_dynamic_module\u001b[39m\u001b[34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[32m    569\u001b[39m final_module = get_cached_module_file(\n\u001b[32m    570\u001b[39m     repo_id,\n\u001b[32m    571\u001b[39m     module_file + \u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m     repo_type=repo_type,\n\u001b[32m    580\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_class_in_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:277\u001b[39m, in \u001b[36mget_class_in_module\u001b[39m\u001b[34m(class_name, module_path, force_reload)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m# reload in both cases, unless the module is already imported and the hash hits\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33m__transformers_module_hash__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) != module_hash:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[43mmodule_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m     module.__transformers_module_hash__ = module_hash\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:940\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/briaai/RMBG-1.4/c052ad0554cf337a16801b23169bba4c4f6a21d7/briarmbg.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mMyConfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RMBGConfig\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mREBNCONV\u001b[39;00m(nn.Module):\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:2045\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:2075\u001b[39m, in \u001b[36m_get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:2073\u001b[39m, in \u001b[36m_get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/importlib/__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:56\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     47\u001b[39m     Conv1D,\n\u001b[32m     48\u001b[39m     apply_chunking_to_forward,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m     prune_linear_layer,\n\u001b[32m     55\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoHfQuantizer, HfQuantizer\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantizers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantizers_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_module_from_name\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msafetensors_conversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auto_conversion\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/quantizers/__init__.py:14\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2024 The HuggingFace Inc. team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoHfQuantizer, AutoQuantizationConfig\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HfQuantizer\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/quantizers/auto.py:32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantizer_bnb_8bit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bnb8BitHfQuantizer\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantizer_gptq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GptqHfQuantizer\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantizer_quanto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantoHfQuantizer\n\u001b[32m     35\u001b[39m AUTO_QUANTIZER_MAPPING = {\n\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mawq\u001b[39m\u001b[33m\"\u001b[39m: AwqQuantizer,\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbitsandbytes_4bit\u001b[39m\u001b[33m\"\u001b[39m: Bnb4BitHfQuantizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquanto\u001b[39m\u001b[33m\"\u001b[39m: QuantoHfQuantizer,\n\u001b[32m     42\u001b[39m }\n\u001b[32m     44\u001b[39m AUTO_QUANTIZATION_CONFIG_MAPPING = {\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mawq\u001b[39m\u001b[33m\"\u001b[39m: AwqConfig,\n\u001b[32m     46\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbitsandbytes_4bit\u001b[39m\u001b[33m\"\u001b[39m: BitsAndBytesConfig,\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquanto\u001b[39m\u001b[33m\"\u001b[39m: QuantoConfig,\n\u001b[32m     51\u001b[39m }\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/quantizers/quantizer_quanto.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_accelerate_available, is_quanto_available, is_torch_available, logging\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuantoConfig\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n",
                        "\u001b[31mImportError\u001b[39m: cannot import name 'is_quanto_available' from 'transformers.utils' (/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/utils/__init__.py)"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import io\n",
                "import torch\n",
                "from PIL import Image\n",
                "import requests\n",
                "import torch.nn.functional as F\n",
                "from transformers import AutoModelForImageSegmentation\n",
                "from torchvision.transforms.functional import normalize\n",
                "\n",
                "\n",
                "# Cargar el modelo\n",
                "model = AutoModelForImageSegmentation.from_pretrained(\"briaai/RMBG-1.4\", trust_remote_code=True)\n",
                "\n",
                "# Función para preprocesar la imagen\n",
                "def preprocess_image(im: np.ndarray, model_input_size: list) -> torch.Tensor:\n",
                "    if len(im.shape) < 3:\n",
                "        im = im[:, :, np.newaxis]\n",
                "    im_tensor = torch.tensor(im, dtype=torch.float32).permute(2, 0, 1)\n",
                "    im_tensor = F.interpolate(torch.unsqueeze(im_tensor, 0), size=model_input_size, mode='bilinear')\n",
                "    image = torch.divide(im_tensor, 255.0)\n",
                "    image = normalize(image, [0.5, 0.5, 0.5], [1.0, 1.0, 1.0])\n",
                "    return image\n",
                "\n",
                "# Función para postprocesar la imagen\n",
                "def postprocess_image(result: torch.Tensor, im_size: list) -> np.ndarray:\n",
                "    result = torch.squeeze(F.interpolate(result, size=im_size, mode='bilinear'), 0)\n",
                "    ma = torch.max(result)\n",
                "    mi = torch.min(result)\n",
                "    result = (result - mi) / (ma - mi)\n",
                "    im_array = (result * 255).permute(1, 2, 0).cpu().data.numpy().astype(np.uint8)\n",
                "    im_array = np.squeeze(im_array)\n",
                "    return im_array\n",
                "\n",
                "# Establecer dispositivo\n",
                "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
                "model.to(device)\n",
                "\n",
                "# Descargar imagen desde URL\n",
                "image_path = \"https://farm5.staticflickr.com/4007/4322154488_997e69e4cf_z.jpg\"\n",
                "response = requests.get(image_path)\n",
                "orig_image = Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n",
                "orig_im = np.array(orig_image)\n",
                "orig_im_size = orig_im.shape[0:2]\n",
                "\n",
                "# Preprocesar\n",
                "model_input_size = [1024, 1024]  # puedes ajustarlo según tu modelo\n",
                "image = preprocess_image(orig_im, model_input_size).to(device)\n",
                "\n",
                "# Inferencia\n",
                "result = model(image)\n",
                "\n",
                "# Post-procesar\n",
                "result_image = postprocess_image(result[0][0], orig_im_size)\n",
                "\n",
                "# Guardar resultado\n",
                "pil_mask_im = Image.fromarray(result_image)\n",
                "no_bg_image = orig_image.copy()\n",
                "no_bg_image.putalpha(pil_mask_im)\n",
                "\n",
                "# Mostrar o guardar\n",
                "no_bg_image.save(\"resultado_sin_fondo.png\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ImportError",
                    "evalue": "cannot import name 'pipeline' from 'transformers' (/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/__init__.py)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m      2\u001b[39m image_path = \u001b[33m\"\u001b[39m\u001b[33mhttps://farm5.staticflickr.com/4007/4322154488_997e69e4cf_z.jpg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m pipe = pipeline(\u001b[33m\"\u001b[39m\u001b[33mimage-segmentation\u001b[39m\u001b[33m\"\u001b[39m, model=\u001b[33m\"\u001b[39m\u001b[33mbriaai/RMBG-1.4\u001b[39m\u001b[33m\"\u001b[39m, trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "\u001b[31mImportError\u001b[39m: cannot import name 'pipeline' from 'transformers' (/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/__init__.py)"
                    ]
                }
            ],
            "source": [
                "from transformers import pipeline\n",
                "image_path = \"https://farm5.staticflickr.com/4007/4322154488_997e69e4cf_z.jpg\"\n",
                "pipe = pipeline(\"image-segmentation\", model=\"briaai/RMBG-1.4\", trust_remote_code=True)\n",
                "pillow_mask = pipe(image_path, return_mask = True) # outputs a pillow mask\n",
                "pillow_image = pipe(image_path) # applies mask on input and returns a pillow image\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ImportError",
                    "evalue": "cannot import name 'PreTrainedModel' from 'transformers' (/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/__init__.py)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForImageSegmentation\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mAutoModelForImageSegmentation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbriaai/RMBG-1.4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_image\u001b[39m(im: np.ndarray, model_input_size: \u001b[38;5;28mlist\u001b[39m) -> torch.Tensor:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(im.shape) < \u001b[32m3\u001b[39m:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:558\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[32m    557\u001b[39m     class_ref = config.auto_map[\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     model_class = \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     _ = hub_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    562\u001b[39m     \u001b[38;5;28mcls\u001b[39m.register(config.\u001b[34m__class__\u001b[39m, model_class, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:581\u001b[39m, in \u001b[36mget_class_from_dynamic_module\u001b[39m\u001b[34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[32m    569\u001b[39m final_module = get_cached_module_file(\n\u001b[32m    570\u001b[39m     repo_id,\n\u001b[32m    571\u001b[39m     module_file + \u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m     repo_type=repo_type,\n\u001b[32m    580\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_class_in_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:277\u001b[39m, in \u001b[36mget_class_in_module\u001b[39m\u001b[34m(class_name, module_path, force_reload)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m# reload in both cases, unless the module is already imported and the hash hits\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33m__transformers_module_hash__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) != module_hash:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[43mmodule_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m     module.__transformers_module_hash__ = module_hash\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:940\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/briaai/RMBG-1.4/c052ad0554cf337a16801b23169bba4c4f6a21d7/briarmbg.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mMyConfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RMBGConfig\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mREBNCONV\u001b[39;00m(nn.Module):\n",
                        "\u001b[31mImportError\u001b[39m: cannot import name 'PreTrainedModel' from 'transformers' (/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/__init__.py)"
                    ]
                }
            ],
            "source": [
                "from transformers import AutoModelForImageSegmentation\n",
                "from torchvision.transforms.functional import normalize\n",
                "model = AutoModelForImageSegmentation.from_pretrained(\"briaai/RMBG-1.4\",trust_remote_code=True)\n",
                "def preprocess_image(im: np.ndarray, model_input_size: list) -> torch.Tensor:\n",
                "    if len(im.shape) < 3:\n",
                "        im = im[:, :, np.newaxis]\n",
                "    # orig_im_size=im.shape[0:2]\n",
                "    im_tensor = torch.tensor(im, dtype=torch.float32).permute(2,0,1)\n",
                "    im_tensor = F.interpolate(torch.unsqueeze(im_tensor,0), size=model_input_size, mode='bilinear')\n",
                "    image = torch.divide(im_tensor,255.0)\n",
                "    image = normalize(image,[0.5,0.5,0.5],[1.0,1.0,1.0])\n",
                "    return image\n",
                "\n",
                "def postprocess_image(result: torch.Tensor, im_size: list)-> np.ndarray:\n",
                "    result = torch.squeeze(F.interpolate(result, size=im_size, mode='bilinear') ,0)\n",
                "    ma = torch.max(result)\n",
                "    mi = torch.min(result)\n",
                "    result = (result-mi)/(ma-mi)\n",
                "    im_array = (result*255).permute(1,2,0).cpu().data.numpy().astype(np.uint8)\n",
                "    im_array = np.squeeze(im_array)\n",
                "    return im_array\n",
                "\n",
                "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
                "model.to(device)\n",
                "\n",
                "# prepare input\n",
                "image_path = \"https://farm5.staticflickr.com/4007/4322154488_997e69e4cf_z.jpg\"\n",
                "orig_im = io.imread(image_path)\n",
                "orig_im_size = orig_im.shape[0:2]\n",
                "image = preprocess_image(orig_im, model_input_size).to(device)\n",
                "\n",
                "# inference \n",
                "result=model(image)\n",
                "\n",
                "# post process\n",
                "result_image = postprocess_image(result[0][0], orig_im_size)\n",
                "\n",
                "# save result\n",
                "pil_mask_im = Image.fromarray(result_image)\n",
                "orig_image = Image.open(image_path)\n",
                "no_bg_image = orig_image.copy()\n",
                "no_bg_image.putalpha(pil_mask_im)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ImportError",
                    "evalue": "cannot import name 'PreTrainedModel' from 'transformers' (/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/__init__.py)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cargar el modelo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mAutoModelForImageSegmentation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbriaai/RMBG-1.4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:558\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[32m    557\u001b[39m     class_ref = config.auto_map[\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     model_class = \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     _ = hub_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcode_revision\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    562\u001b[39m     \u001b[38;5;28mcls\u001b[39m.register(config.\u001b[34m__class__\u001b[39m, model_class, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:581\u001b[39m, in \u001b[36mget_class_from_dynamic_module\u001b[39m\u001b[34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[32m    569\u001b[39m final_module = get_cached_module_file(\n\u001b[32m    570\u001b[39m     repo_id,\n\u001b[32m    571\u001b[39m     module_file + \u001b[33m\"\u001b[39m\u001b[33m.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m     repo_type=repo_type,\n\u001b[32m    580\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_class_in_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:277\u001b[39m, in \u001b[36mget_class_in_module\u001b[39m\u001b[34m(class_name, module_path, force_reload)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m# reload in both cases, unless the module is already imported and the hash hits\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33m__transformers_module_hash__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) != module_hash:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[43mmodule_spec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m     module.__transformers_module_hash__ = module_hash\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, class_name)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:940\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/briaai/RMBG-1.4/c052ad0554cf337a16801b23169bba4c4f6a21d7/briarmbg.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mMyConfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RMBGConfig\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mREBNCONV\u001b[39;00m(nn.Module):\n",
                        "\u001b[31mImportError\u001b[39m: cannot import name 'PreTrainedModel' from 'transformers' (/workspaces/ML-WEBAPP-USING-STREAMLIT-JesusCastanedam/.venv/lib/python3.11/site-packages/transformers/__init__.py)"
                    ]
                }
            ],
            "source": [
                "# Cargar el modelo\n",
                "model = AutoModelForImageSegmentation.from_pretrained(\"briaai/RMBG-1.4\", trust_remote_code=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
